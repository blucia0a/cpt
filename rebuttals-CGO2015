Performance Issues> 
Reviewer A: "over-claims its performance results, talking about LWS being fast enough for production"

Reviewer D: Are overheads acceptable in production? Does claiming they are weaken the paper? 
            "I've personally sat in industry meetings where a 5% overhead was unacceptable"

Reviewer D:  Do the server applications hide instrumentation latency with I/O?


Other Approaches and Information>
Reviewer A: also useful for sequential bugs
Reviewer B: LWS does not provide complete history variable, root cause info, or computation that produced value
Reviewer C: Main Weakness - "the idea is too simple and the paper does not explore alternative strategies"
            "one wonders why it has not been done before"
            "can be extended by keeping track of additional information in different ways"
            "conceivable that race detection ... would detect ... all examples in the evaluation" <<-- nope!  not all races!
Reviewer C: Keeping the last K > 1 writes would be useful (see B above)


Comparison to Octet>
Reviewer D: heavily overlaps with Octet
            "Octet offers similar performance (in addition to soundness in the presence of data races)"
Reviewer D: Compare to unpublished C++11 octet implementation


Value of CTraps>
Reviewer C: "CTraps seems superfluous since strategy is not use for any studies other than to evaluate its performance"


Library Code>
Reviewer A: Is the LWS misleading if a library is the real last writer?


Implementation Questions>
Reviewer A: how did you handle inline assembly?
Reviewer A: 32- vs. 64-bit applications? How did you encode program points?
Reviewer A: What is the thread identifier?  How obtained efficiently?
Reviewer A: Were the server apps CPU-bound or not?
Reviewer C: Why is the shadow array 2GB?


Lossy Hash Table>
Reviewer B: Lossy hash table makes results imprecise
Reviewer C: What is a lossy resolution for hash collisions?


Races in the LWT>
Reviewer B: Concerned about racy LWT


Evaluation Questions>
Reviewer C: how many executions to make httrack and transmission fail?
Reviewer E: Debugging evaluation is subjective


Other Issues>
Reviewer C: "Dependences are order constraints. They do not arise in parallel programs". Use other terms for W-W and R-W conflicts
Reviewer E: "method of tracking the provenance of (bad) data values"
Reviewer E: figures are too small, must cut to be accepted
